---
title: QEUR23_VTFDEV13: 技術まとめ ～ SOARTCメトリックスによる簡単な外観検査自動機
date: 2024-03-10
tags: ["QEUシステム", "メトリックス", "Python言語", "Vision Transformer", "LLM", "データセット", "Fine-tuning", "イノベーション"]
excerpt: Vision Transformer(ViT)をやってみる
---

## 技術まとめ ～ SOARTCメトリックスによる外観検査自動機

### 【発明の名称】 
**SOARTCメトリックスを使用した外観検査自動機**

### 【技術分野】  
### 【０００１】
本発明はコンピューターによる外観検査自動機に関するものです。

### 【背景技術】
### 【０００２】
画像判別用の機械学習ロジックは、すでに提案されており、多くの成果が挙げられています(図1)。なかでもCNN（Convolutional Neural Network:畳み込みニューラルネットワーク）は、高い判別能力があると言われています。

**(図1:画像判別のコンペの歴史)**

![imageJRL9-14-1](/2024-03-10-QEUR23_VTFDEV13/imageJRL9-14-1.jpg)

### 【０００３】
ただし、これらの画像判別で成功した技術(図2)を、そのまま外観検査による異常検出に使用した場合には必ずしも良い結果が得られるとは限りません。一方、最近ではVision Transformer（以下ViT）という技術が提案されており、この手法の方がCNNよりも外観検査(異常検出)用に優れている可能性があります。CNNは畳み込みよって画像情報を集約して特徴ベクトルを作るため、個体判別に優れています(図3)。しかし、CNNはモデルの構造(図4)の特性上、被検査体の特徴が空間的に分離した場合の判別の精度はよくありません。一方、ViTは自然言語処理から派生した技術であるので、そのような制限はありません。ViTを品質管理に適用した学術成果が論文になっている事例もあります(図5)。

**(図2: 画像判別の例)**

![imageJRL9-14-2](/2024-03-10-QEUR23_VTFDEV13/imageJRL9-14-2.jpg)

**(図3: 畳み込みニューラルネットワークの構造)**

![imageJRL9-14-3](/2024-03-10-QEUR23_VTFDEV13/imageJRL9-14-3.jpg)

**(図4:Vision Transformerの構造)**

![imageJRL9-14-4](/2024-03-10-QEUR23_VTFDEV13/imageJRL9-14-4.jpg)

**（図5:学術成果の例）**

![imageJRL9-14-5](/2024-03-10-QEUR23_VTFDEV13/imageJRL9-14-5.jpg)


### 【０００４】
そのほか、既述のCNNやViT以外にも多くの異常検出手法が提案されており、プリント基板の品質管理などの転写性のきわめて高い製品を中心に実用化されています。代表的な手法を挙げると以下の通りです。

- **画像差分法**
- **距離を計測する方法**
- **教師あり学習（ディープラーニング）**
**※オートエンコーダ―(VAE)はディープラーニングと画像差分法の中間的手法と考えられます**

### 【０００５】
「画像差分法」や「距離を計測する方法」は適用対象が限られる可能性があります。一方、汎用検査用としてCNNやViT(Vision Transformer)の個体判別の技術を異常判別に適用するのが比較的有望だと考えられています。その中でも、本発明者が前報で提案したSOART3メトリックスで合成画像を作成し、ViTに入力して異常を検出する方法は、複雑な形状をもつ物体の外観検査(図6)に有望と考えられます。

**（図6:被検査品の事例 - プラスチック射出成型品）**

![imageJRL9-14-6](/2024-03-10-QEUR23_VTFDEV13/imageJRL9-14-6.jpg)

### 【０００６】
前報告の発明（以下、前発明）では、高解像度(ex 1000x1000)の画像を使用して初めて検出できる微小な欠陥でも、画像の本来の情報量を落とさずに圧縮することにより標準サイズ(224x224)のViTモデルを使用することができます。このため、前発明では従来法と比較して学習データの準備コストと計算コストを掛けずに高精度の予測をすることができます。本発明でも前発明のノウハウを一部使用するため、以下、その技術について簡潔に説明します。

### 【０００７】
タグチ・メソッドのRT法は、SN比(η)として標準ベクトルと感度(β)による補正後の計測ベクトルを比較したユーグリッド距離を使用しています(図7)。一方、SOART3法はRT法を3次元メトリックス出力(図8)に拡張し、それらをRGB画像などに出力します。そのシステムの構成を図8に示します。

**（図7:RT法の原理）**

![imageJRL9-14-7](/2024-03-10-QEUR23_VTFDEV13/imageJRL9-14-7.jpg)

**（図8:SOART3法のシステム構成図）**

![imageJRL9-14-8](/2024-03-10-QEUR23_VTFDEV13/imageJRL9-14-8.jpg)

### 【０００８】
SOART3法は標準ベクトルと計測ベクトル間の距離を普遍化して、ミンコフスキー距離を考えています(図9)。この距離はパラメタのｐ値を変化させることで、マンハッタン距離(p=0)～チェビシェフ距離(p=∞)まで変化することができます。つまり、SOART3法では、RT法のユーグリット距離のかわりに2つの独立したメトリックスに分離させて3次元化したいので、マンハッタン距離とチェビシェフ距離を使っているのです(図10)。

**（図9:ミンコフスキー距離の定義）**

![imageJRL9-14-9](/2024-03-10-QEUR23_VTFDEV13/imageJRL9-14-9.jpg)

**（図10:SOART3法の考え方）**

![imageJRL9-14-10](/2024-03-10-QEUR23_VTFDEV13/imageJRL9-14-10.jpg)

### 【０００９】
SOART3法の処理プロセスをPythonプログラムで記述した事例を示します。まずは、標準ベクトル(x)と計測ベクトル(y)のデータから感度（β）を計算します。その後、感度で補正したβxと計測ベクトルyの間のチェビシェフ距離とマンハッタン距離をそれぞれ計算します。チェビシェフ距離とマンハッタン距離は同じベクトル(βx, y)から生成しており、このままでは2つの距離には若干の相関があると思われるので、チェビシェフ距離は対数変換したあとでマンハッタン距離との差を取っています。対数変換は、値の挙動を線形化し、学習モデルを小さくするために適用しています。

```python
# soaRT3メトリックスを計算する
def calc_soaRT3(tsr_sig_array, tsr_tani_array): 

    # データの抽出
    y = tsr_sig_array
    x = tsr_tani_array
    #print(y)
    #print(x)

    # 感度(β)を計測
    xx = np.dot(x,x) + 0.0001
    xy = np.dot(x,y) + 0.0001
    beta = xy/xx

    # チェビシェフ距離を計測
    vDistance = chebyshev(y,beta*x)

    # マンハッタン距離を計測
    mDistance = np.linalg.norm(y - beta*x, ord=1)
    #print("mDistance: ", mDistance.item())
    
    # 値の対数変換
    log_beta  = math.log(beta)
    log_yita = math.log(mDistance+1.0)
    log_gamma = math.log(vDistance+1.0) - log_yita
    
    return log_beta, log_yita, log_gamma
```


### 【００１０】
標準画像（標準ベクトル）と計測画像（計測ベクトル）を処理すると、SOART3メトリックスが得られます。そのメトリックスをピクセルごとに並べると、以下のようなSOART3合成画像を生成できます（図11）。

**（図11: SOART3合成画像の例）**

![imageJRL9-14-11](/2024-03-10-QEUR23_VTFDEV13/imageJRL9-14-11.jpg)

### 【００１１】
前発明のコネクタの端子抜け検査への適用事例として、正常、不良（傾きモード）、不良（後退モード）の学習・検証データを使用した実験の結果を紹介します(図12)。

**(図12: 不良モードの定義)**

![imageJRL9-14-12](/2024-03-10-QEUR23_VTFDEV13/imageJRL9-14-12.jpg)

### 【００１２】
前発明のViTを使うと、異常モードの分類(検出)ができるだけでなく、Attention Mapの機能を使って、異常個所を可視化することもできます (図13)。

**（図13：アテンション・マップの例）**

![imageJRL9-14-13](/2024-03-10-QEUR23_VTFDEV13/imageJRL9-14-13.jpg)

### 【発明の概要】
### 【発明が解決しようとする課題】

### 【００１３】
外観検査の実務を考えると、入力する画像は前述の1000 x1000の解像度でも不足する場合があります。検出すべき不良の種類によっては、4000x4000以上の高解像度の入力が必要になります（図14）。もちろん、検査すべき領域を分割させて個別に予測する方法もあります。しかし、その場合にはViTエンジンが複数個必要となりコストがかかります。

**（図14:高解像度が必要な不良の例）**

![imageJRL9-14-14](/2024-03-10-QEUR23_VTFDEV13/imageJRL9-14-14.jpg)

### 【００１４】
さらに言うと、外観検査自動機の低コスト化のためには複雑なViTを使わずに予測・可視化してくれること。さらにいうと、より簡単な予測法によりRaspberry Pi(図15)などの低価格のエッジ・コンピューターで検査をしてくれることが望ましいでしょう。

**（図15: Raspberry Pi5のスペック）**

![imageJRL9-14-15](/2024-03-10-QEUR23_VTFDEV13/imageJRL9-14-15.jpg)

### 【課題を解決するための手段】

### 【００１５】
本発明では、前発明のSOART3法とViT(Vision Transformer)の考え方を拡張して合成画像を生成して、外観検査結果を可視化します。本発明（以下、SOARTC法）は、2段階の解析ステップで構成されています。そのうち、STEP1(上)のSOART3法のスキームに畳み込みを追加しています(図16)。そして、**STEP2(下)は、異常度の計測であり(図17)、前発明のViTに相当します**。

**(図16: SOARTCメトリックスの構造：上)**

![imageJRL9-14-16](/2024-03-10-QEUR23_VTFDEV13/imageJRL9-14-16.jpg)

**(図17: SOARTCメトリックスの構造：下)**

![imageJRL9-14-17](/2024-03-10-QEUR23_VTFDEV13/imageJRL9-14-17.jpg)

### 【００１６】
SOART3法は、標準画像と計測画像の２つの画像を入力します。それに対し、SOARTC法の第1段階(STEP1)目では入力した画像に畳み込みを行って自己類似度メトリックスを生成します。その畳み込みを行うための部品群は、ユーザーが自分で設計する必要があります。ここで、DATUMは標準マトリックスを生成するための部品であり、その他の部品は計測マトリックス用に設計されています。図18は、畳み込み設計を5x5にした例ですが、他の大きさ(11x11など)にすることができます。

**（図18:畳み込み部品）**

![imageJRL9-14-18](/2024-03-10-QEUR23_VTFDEV13/imageJRL9-14-18.jpg)

### 【００１７】
外観検査システムに入力された画像は、SOARTCメトリックスを生成するために所定の大きさに切り取られます。図19の事例では、22x22の大きさに切り取られています。これは、畳み込み部品のサイズが11x11であり、畳み込みによって2x2の自己類似度マトリックスを生成するためです。

**（図19:自己類似度マトリックスの設計-2x2の場合）**

![imageJRL9-14-19](/2024-03-10-QEUR23_VTFDEV13/imageJRL9-14-19.jpg)

### 【００１８】
このように生成された自己類似度マトリックスがSOART3法で処理されて、3つのメトリックス（β、η、γ）に変換されます。その結果、第1段階目のステップでの出力は、図20のような3x6(畳み込み部品)=18種のベクトルになります。この手法は、自己類似度を用いているという点でAttentionに近い方法です(図21)。

**（図20:SOARTC第一段階の出力）**

![imageJRL9-14-20](/2024-03-10-QEUR23_VTFDEV13/imageJRL9-14-20.jpg)

**(図21:Attentionスキームの構造)**

![imageJRL9-14-21](/2024-03-10-QEUR23_VTFDEV13/imageJRL9-14-21.jpg)

### 【００１９】
そして第2段目では、第1段目の出力を入力としています。以下、種々の図形をSOARTCで解析した事例を見ながら第2段目の手法を説明します。ここで、標準画像は赤枠で示した角を丸めた正方形であり、その他の図形が計測画像になります。

**（図22:テスト画像と図形）**

![imageJRL9-14-22](/2024-03-10-QEUR23_VTFDEV13/imageJRL9-14-22.jpg)

### 【００２０】
第二段階目では、第一段階目が出力した3x6=18種のメトリックスを、beta(β)-yita(η)-gamma(γ)の種類別に分類し、標準画像のメトリックス値(X)と計測画像のメトリックス値(Y)の散布図で比較します。すると、β（傾き）=1の0点一次式からの外れ度合いが異常度になります。

**(図23:SOART3三種メトリックスで散布図を描いた結果)**

![imageJRL9-14-23](/2024-03-10-QEUR23_VTFDEV13/imageJRL9-14-23.jpg)

### 【００２１】
これらのプロットが傾きがβ=1の0点一次式から外れた度合いを数量化します。その数量化の方法は、**ユーザーの考え方により選択可能**です。ここでは、標準ベクトルと計測ベクトル間のミンコフスキー距離をつかいました。

```python
# ----------------
# soaRTCメトリックス(no2)を計算する
def calc_soaRTC_no2(tsr_sig_array, tsr_tani_array): 

    # データの抽出
    y = tsr_sig_array
    x = tsr_tani_array
    #print(y)
    #print(x)
 
    # ミンコフスキー距離を計測
    vDistance = minkowski(y, x, 4) #p=4 
 
    return vDistance
```

### 【００２２】
このように、SOARTC法は、入力画像のサイズを大きくすることがとても簡単です。畳み込み部品を大きくしてもよいし、ストライド量を大きくすることもできます。さらには、2x2の自己類似度マトリックスをより大きくして4x4にしてもよいのです。

**（図24:両目法による立体計測のしくみ）**

![imageJRL9-14-24](/2024-03-10-QEUR23_VTFDEV13/imageJRL9-14-24.jpg)

### 【００２３】
SOARTC法を使えば、左右カメラの検査画像を合成して、**立体品の品質を検査することも容易です**。

### 【実施例1】
### 【００２４】
この実施例では、図25のような様々な正方形の画像を作成してSOARTCのメトリックス値を計測してみます。画像には、大きさ、色、回転、移動(X,Y)の要素が加えられていますが、図形の対比として三角形についても同様な画像を準備しました。

**(図25：実験に使われた画像-正方形の場合)**

![imageJRL9-14-25](/2024-03-10-QEUR23_VTFDEV13/imageJRL9-14-25.jpg)

**(図26: 準備したテスト画像のリスト)**

![imageJRL9-14-26](/2024-03-10-QEUR23_VTFDEV13/imageJRL9-14-26.jpg)

### 【００２５】
回転角度とSOARTCメトリックスの関係をグラフで評価しました。図27の3つのグラフは、それぞれ回転角度とbeta-yita-gammaメトリックスの関係を表現しており、各グラフの中では正方形と三角形との比較をしています。これを見ることにより、図形の差異、回転、移動量がメトリックスに与える影響を評価することができます。

**(図27: SOARTC処理で計算した3種のメトリックスの表)**

![imageJRL9-14-27](/2024-03-10-QEUR23_VTFDEV13/imageJRL9-14-27.jpg)

**(図28: SOARTCメトリックスのグラフ化-回転と移動)**

![imageJRL9-14-28](/2024-03-10-QEUR23_VTFDEV13/imageJRL9-14-28.jpg)

### 【００２６】
ここで得られた知見は、SOARTC法を外観検査に使った場合には、被検査体の取り付け時に少しのずれ（回転、移動）が発生したとしても、その画像の図形の異常を十分に検出できることです。次に、同様に図形の大きさと色（明るさ）の影響について評価をします。

**(図29:  SOARTCメトリックスのグラフ化-大きさと色)**

![imageJRL9-14-29](/2024-03-10-QEUR23_VTFDEV13/imageJRL9-14-29.jpg)

### 【００２７】
一方、図形の大きさと色の変化とメトリックスの関係については、これらの変化量が図形の差異に近い大きさを持っていることがわかりました。つまり、SOARTC法で外観検査機をつくる場合には大きさ（カメラと被写体の距離）と明るさ（ライトと被写体の距離）の安定性に注意が必要です。逆にいえば、SOART法は大きさや色の異常を検出することが容易であることがわかりました。

### 【実施例2】
### 【００２８】
次の事例として、SOARTC法をより実際の外観検査に近い環境で使用したときのシミュレーションを行いました。ワイヤーハーネスのコネクタの端子抜けを検査しました。ここで使用する画像は、三次元CGソフト(Blender)で作成しました。このように、CGソフト（図30）で画像を作成すると、被検査体に回転や移動に微妙な差異を付けた画像を大量に生成できます（図31）。

**（図30：角柱CGモデル）**

![imageJRL9-14-30](/2024-03-10-QEUR23_VTFDEV13/imageJRL9-14-30.jpg)

**（図31：角柱コネクタの画像群）**

![imageJRL9-14-31](/2024-03-10-QEUR23_VTFDEV13/imageJRL9-14-31.jpg)

### 【００２９】
SOARTC法に使用する標準画像として、正常状態のコネクタの画像を複数枚準備し、それらを平均しました。また、計測（外観検査）する画像として、左上のピンが傾いた画像を使用しました。

**（図32：標準画像）**

![imageJRL9-14-32](/2024-03-10-QEUR23_VTFDEV13/imageJRL9-14-32.jpg)

**（図33： 計測画像）**

![imageJRL9-14-33](/2024-03-10-QEUR23_VTFDEV13/imageJRL9-14-33.jpg)

### 【００３０】
まず最初にSOARTCメトリックスを用いたRGB画像を見てみましょう。SOARTCメトリックスは、beta-yita-gammaという３種類の数値が得られるため、その値をカラー画像に変換したものです。この画像によって、標準画像と計測画像の差異を見ることができます。

**（図34：SOARTC解析結果～RGB画像）**

![imageJRL9-14-34](/2024-03-10-QEUR23_VTFDEV13/imageJRL9-14-34.jpg)

### 【００３１】
このRGB画像をグレースケールに変換した結果を図35に示します。ここで、RGB画像をグレースケールにする変換式は、ユーザーが異常を発見しやすいように自分で決める（Gray=αxRed+βxGreen+γxBlue）のがよいでしょう。

**（図35：SOARTC解析結果～グレースケール画像）**

![imageJRL9-14-35](/2024-03-10-QEUR23_VTFDEV13/imageJRL9-14-35.jpg)

### 【００３２】
異常個所をより目立ちやすくするために、グレースケール画像をsoftmax関数で処理すると図36の画像が得られます。

**(図36: SOARTC解析結果～softmax関数処理後)**

![imageJRL9-14-36](/2024-03-10-QEUR23_VTFDEV13/imageJRL9-14-36.jpg)

### 【００３３】
より分かりやすい例として、正常な被検査品の画像の上に文字を貼りつけた画像をSOARTC法で処理をしました(図37)。すると、処理した画像に文字が浮き上がっていることがわかります。

**(図37: 正常な被検査品の画像の上に文字を貼りつけた場合)**

![imageJRL9-14-37](/2024-03-10-QEUR23_VTFDEV13/imageJRL9-14-37.jpg)

**(図38: SOARTC解析結果)**

![imageJRL9-14-38](/2024-03-10-QEUR23_VTFDEV13/imageJRL9-14-38.jpg)

### 【００３４】
このように、SOARTC処理を使えば、ViTで出力できるAttention Mapに相当する異常部位をハイライトした画像がえられます。ただし、SOARTCの場合には、標準画像と計測画像の差異を示す画像なので、検査が目的とする異常以外の画像の傾きや回転なども表示されます。

### 【産業上の利用可能性】
### 【００３５】
本発明では、大きな画像を小さなViTモデルで解析するための特徴量エンジアリング手法として、SOARTCメトリックスを提案しました。同時に、出力した画像をアテンション・マップに相応するものとして外観検査のアシスト用に使用することもできます。

**(図39:欠品検査への応用事例)**

![imageJRL9-14-39](/2024-03-10-QEUR23_VTFDEV13/imageJRL9-14-39.jpg)

### 【００３６】
本発明により標準画像と計測画像の差異を比較、可視化できるので、その出力画像をSVM（サポートベクトルマシン）などの比較的簡単なモデルに入力して外観検査の自動化ができるでしょう。特に、欠品検査などの比較的簡単な自動化案件には容易に適用できるでしょう。


## ～ まとめ ～

### ・・・ 以下、発明の補足です ・・・

QEU:FOUNDER: “さて、本発明の補足です。本発明の本意は、あくまで**「Vision Transformerの前処理（特徴量エンジニアリング）である」**ことを、特に強調しておきたいです。”

![imageJRL9-14-40](/2024-03-10-QEUR23_VTFDEV13/imageJRL9-14-40.jpg)

C部長: “このRGB色の配分には、「2つの画像の差異を特徴量として抽出した結果である」という意味がありますからね。あの・・・。この技術について、現場の人と話をしていたら、「この技術は画像差分と何が違うんだ？」という言葉がでてきました。”

QEU:FOUNDER: “ん？C部長は、ちゃんと回答しただろうね？”

![imageJRL9-14-41](/2024-03-10-QEUR23_VTFDEV13/imageJRL9-14-41.jpg)

C部長: “いやあ・・・。「Quality」という文字が浮き出てきたので、「そういう考え方もあるなあ・・・」と思った次第です。”

QEU:FOUNDER: “おいおい・・・。SOARTC処理は、その画像を粗くしたときに差が出てくるんです。画像差分法であれば、モザイク化されて粗くなった画像には全く意味がありません。しかし、**SOARTC法を適切に使用した情報には画像が粗くなっても予測に十分な特徴量が残っている**んです。今回は皆に「一目瞭然にわかる」ように、「文字(Quality)を浮かびださせる」というパフォーマンスをやったのが逆にまずかったねえ・・・。”

![imageJRL9-14-42](/2024-03-10-QEUR23_VTFDEV13/imageJRL9-14-42.jpg)

D先生: “いにしえのタグチ・メソッドは、これで生き残るでしょうか？”

QEU:FOUNDER: “またもや**「あってよかったRT法」**と思いました。ただし、RT法じゃなくRTメトリックスですがね・・・。”

![imageJRL9-14-43](/2024-03-10-QEUR23_VTFDEV13/imageJRL9-14-43.jpg)

D先生: “FOUNDERの意見としては、あとはT法だけでしょ？長期的に生き残れるのは・・・。”

QEU:FOUNDER: “最近、T法の応用をトライしていない。もうちょっとは開発したいとおもっています。いつもネタを考えているんだけど、思いつかないなあ・・・。”

### [＞寄付のお願い(click here)＜](https://www.paypal.com/paypalme/QEUglobal?v=1&utm_source=unp&utm_medium=email&utm_campaign=RT000481&utm_unptid=29844400-7613-11ec-ac72-3cfdfef0498d&ppid=RT000481&cnac=HK&rsta=en_GB%28en-HK%29&cust=5QPFDMW9B2T7Q&unptid=29844400-7613-11ec-ac72-3cfdfef0498d&calc=f860991d89600&unp_tpcid=ppme-social-business-profile-creat-ed&page=main%3Aemail%3ART000481&pgrp=main%3Aemail&e=cl&mchn=em&s=ci&mail=sys&appVersion=1.71.0&xt=104038)


D先生: “あっ・・・。さっき、C部長の現場の検査員からクレームがあったそうです。A君とB君が早速外観検査自動機を作ってくれたのが、不満があるそうですよ・・・。（次回につづく）”


